{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using dfe_cont_store.generation.ai\n",
    "\n",
    "This notebook demonstrates the usage of the `ai` module from the `dfe_cont_store.generation` package. \n",
    "\n",
    "## Overview\n",
    "\n",
    "The `ai` module offers a set of functions to:\n",
    "1. Create system, user, and assistant messages\n",
    "2. Generate chat completions using OpenAI's models\n",
    "3. Handle structured responses with custom JSON schemas/Pydantic objects\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Automatic OpenAI Settings**: The module automatically creates a default OpenAI client using predefined settings, simplifying the setup process.\n",
    "- **Flexible Message Creation**: Easily create system, user, and assistant messages for your conversations.\n",
    "- **Structured Responses**: Support for generating responses in specific JSON formats using custom schemas.\n",
    "- **Token Counting**: Automatic tracking of input and output token usage for each request.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Ensure you have the `dfe_cont_store` package installed and properly configured.\n",
    "- An active OpenAI API key should be set up in your environment variables or configuration files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oak_hackaton.generation import ai \n",
    "import json\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example simple usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens used = 27\n",
      "Output tokens used = 3\n",
      "Content response = Woof!\n"
     ]
    }
   ],
   "source": [
    "# Create messages \n",
    "sys_msg = ai.create_system_msg(\"You are a dog who can only response with 'woof'\")\n",
    "usr_msg = ai.create_user_msg(\"Hello chat GPT\")\n",
    "\n",
    "# Create a chat completion request \n",
    "response = ai.chat_completion(messages=[sys_msg, usr_msg])\n",
    "\n",
    "# Print response \n",
    "print(f\"Input tokens used = {response.input_token_count}\")\n",
    "print(f\"Output tokens used = {response.output_token_count}\")\n",
    "print(f\"Content response = {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens used = 44\n",
      "Output tokens used = 5\n",
      "Content response = Woof woof!\n"
     ]
    }
   ],
   "source": [
    "# If we want to go back to the AI and keep the history, we can do this easily \n",
    "assistant_msg = ai.create_assistant_msg(response.content)\n",
    "new_usr_msg = ai.create_user_msg(\"Wow you really are a dog\")\n",
    "new_response = ai.chat_completion(messages = [sys_msg, usr_msg, assistant_msg, new_usr_msg])\n",
    "\n",
    "# Print response \n",
    "print(f\"Input tokens used = {new_response.input_token_count}\")\n",
    "print(f\"Output tokens used = {new_response.output_token_count}\")\n",
    "print(f\"Content response = {new_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example using json schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content response:\n",
      "{\n",
      "  \"countries\": [\n",
      "    {\n",
      "      \"name\": \"England\",\n",
      "      \"capital\": \"London\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Scotland\",\n",
      "      \"capital\": \"Edinburgh\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Wales\",\n",
      "      \"capital\": \"Cardiff\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Northern Ireland\",\n",
      "      \"capital\": \"Belfast\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create messages \n",
    "sys_msg = ai.create_system_msg(\"You are a helpful assistant\")\n",
    "usr_msg = ai.create_user_msg(\"What are the constituent countries of the UK and their capitals?\")\n",
    "\n",
    "# Create a json schema \n",
    "json_schema = {\n",
    "    \"name\": \"uk_countries\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"countries\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"name\": {\"type\": \"string\"},\n",
    "                        \"capital\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"name\", \"capital\"],\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"countries\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}\n",
    "\n",
    "# Create a chat completion request \n",
    "response = ai.chat_completion(messages=[sys_msg, usr_msg], structured_response = True, json_schema=json_schema)\n",
    "\n",
    "# Parse the content as JSON\n",
    "parsed_content = json.loads(response.content)\n",
    "\n",
    "# Print the JSON in a formatted way\n",
    "print(\"Content response:\")\n",
    "print(json.dumps(parsed_content, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same example using a Pydantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content response:\n",
      "{\n",
      "  \"countries\": [\n",
      "    {\n",
      "      \"name\": \"England\",\n",
      "      \"capital\": \"London\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Scotland\",\n",
      "      \"capital\": \"Edinburgh\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Wales\",\n",
      "      \"capital\": \"Cardiff\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Northern Ireland\",\n",
      "      \"capital\": \"Belfast\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define a Pydantic model for a country\n",
    "class Country(BaseModel):\n",
    "    name: str\n",
    "    capital: str\n",
    "\n",
    "# Define a Pydantic model for a list of countries\n",
    "class UKCountries(BaseModel):\n",
    "    countries: List[Country]\n",
    "\n",
    "# Create a chat completion request \n",
    "response = ai.chat_completion(messages=[sys_msg, usr_msg], structured_response = True, pydantic_model=UKCountries)\n",
    "\n",
    "# Convert the pydantic model to a json string\n",
    "print(\"Content response:\")\n",
    "print(response.content.model_dump_json(indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oak_hackaton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
